import streamlit as st
import pandas as pd
from typing import Optional, List, Dict, Union
from datetime import datetime
from io import BytesIO

# ÎÇ†Ïßú ÌòïÏãùÏù¥ Í∞ÄÏû• ÎßéÏù¥ Îì§Ïñ¥ÏûàÎäî Ïó¥Ïùò Ïù∏Îç±Ïä§Î•º Ï∞æÎäî Ìï®Ïàò
def find_date_start_col(df: pd.DataFrame, sample_row_count: int = 10) -> int:
    def is_date(x: Union[str, datetime]) -> bool:
        try:
            pd.to_datetime(x)
            return True
        except:
            return False

    date_counts = [
        sum(df.iloc[:sample_row_count, col_idx].apply(is_date))
        for col_idx in range(df.shape[1])
    ]
    best_col = date_counts.index(max(date_counts))

    if date_counts[best_col] == 0:
        raise ValueError("No date column found")

    return best_col

# ÎÇ†ÏßúÍ∞Ä Ìè¨Ìï®Îêú Ï≤´ Î≤àÏß∏ ÌñâÏùò Ïù∏Îç±Ïä§Î•º Ï∞æÎäî Ìï®Ïàò
def find_date_row(df: pd.DataFrame, date_start_col: Optional[int] = None,
                  min_date_count: int = 1, max_row_check: int = 20) -> int:
    if date_start_col is None:
        date_start_col = find_date_start_col(df)

    def is_date(x: Union[str, datetime, pd.Timestamp]) -> bool:
        if isinstance(x, (pd.Timestamp, datetime)):
            return True
        if isinstance(x, str):
            try:
                pd.to_datetime(x)
                return True
            except:
                return False
        return False

    for i in range(min(max_row_check, len(df))):
        row = df.iloc[i, date_start_col:]
        if row.apply(is_date).sum() >= min_date_count:
            return i

    raise ValueError("No date row found")

# ÎÇ†ÏßúÍ∞Ä Îì§Ïñ¥ ÏûàÎäî ÏÖÄÎì§Ïùò Ïó¥ Ïù∏Îç±Ïä§Î•º Ïã§Ï†ú ÎÇ†Ïßú Í∞íÍ≥º Îß§ÌïëÌïòÎäî Ìï®Ïàò
def get_date_mapping(df: pd.DataFrame, date_row_index: int,
                     date_start_col: Optional[int] = None) -> Dict[int, pd.Timestamp]:
    if date_start_col is None:
        date_start_col = find_date_start_col(df)

    date_row = df.iloc[date_row_index, date_start_col:]
    dates = pd.to_datetime(date_row, errors='coerce')

    mapping = {}
    for col_idx, date in zip(range(date_start_col, len(df.columns)), dates):
        if pd.notna(date):
            mapping[col_idx] = date

    return mapping

# Ï∏°Ï†ï Îç∞Ïù¥ÌÑ∞Î•º Ï∂îÏ∂úÌïòÎäî Ìï®Ïàò
def extract_measurement_data(
        df: pd.DataFrame,
        info_dict: Dict[str, str],
        date_mapping: Dict[int, pd.Timestamp],
        date_row_index: int,
        search_cols: List[int] = list(range(0, 11))
) -> pd.DataFrame:
    results = []
    search_cols = [col for col in search_cols if col < df.shape[1]]

    point_indices = []
    for i in range(date_row_index, len(df)):
        for col in search_cols:
            if col >= df.shape[1]:
                continue
            cell_value = df.iloc[i, col]
            if str(cell_value).strip() == 'Ï∏°Ï†ïPOINT':
                ctq_col = col + 1
                if ctq_col < df.shape[1]:
                    ctq_name = df.iloc[i, ctq_col]
                    if pd.notna(ctq_name):
                        point_indices.append((i, ctq_name))
                break

    for idx, (start_idx, ctq_name) in enumerate(point_indices):
        if idx + 1 < len(point_indices):
            end_idx = point_indices[idx + 1][0]
        else:
            end_idx = start_idx + 1
            while end_idx < len(df):
                if df.iloc[end_idx, min(date_mapping.keys()):].notna().sum() > 0:
                    end_idx += 1
                else:
                    break

        for i in range(start_idx, end_idx):
            for col in date_mapping:
                if col < df.shape[1] and i < df.shape[0]:
                    value = df.iloc[i, col]
                    if pd.notna(value):
                        results.append({
                            '1Ï∞® ÏóÖÏ≤¥Î™Ö': str(info_dict.get("1Ï∞® ÏóÖÏ≤¥Î™Ö", "")).strip(),
                            'ÏßÄÏó≠Î™Ö': str(info_dict.get("ÏßÄÏó≠Î™Ö", "")).strip(),
                            '2Ï∞®ÏóÖÏ≤¥Î™Ö': str(info_dict.get("2Ï∞®ÏóÖÏ≤¥Î™Ö", "")).strip(),
                            'Î™®Îç∏Î™Ö': str(info_dict.get("Î™®Îç∏Î™Ö", "")).strip(),
                            'Ï∏°Ï†ïÏûê': str(info_dict.get("Ï∏°Ï†ïÏûê", "")).strip(),
                            'Ï∏°Ï†ïÏû•ÎπÑ': str(info_dict.get("Ï∏°Ï†ïÏû•ÎπÑ", "")).strip(),
                            'Î∂ÄÌíàÎ™Ö': str(info_dict.get("Î∂ÄÌíàÎ™Ö", "")).strip(),
                            'CTQ/P Í¥ÄÎ¶¨Ìï≠Î™©Î™Ö': str(ctq_name).strip(),
                            'Ï∏°Ï†ïÏùºÏûê': date_mapping[col],
                            'Ï∏°Ï†ïÍ∞í': value,
                            'Part No': str(info_dict.get("Part No", "")).strip()
                        })

    return pd.DataFrame(results)

# Í¥ÄÎ¶¨Î≤àÌò∏Î•º Îß§ÌïëÌïòÎäî Ìï®Ïàò
def add_management_code(results_df: pd.DataFrame, master_key_df: pd.DataFrame) -> pd.DataFrame:
    merge_keys = ["1Ï∞® ÏóÖÏ≤¥Î™Ö", "ÏßÄÏó≠Î™Ö", "2Ï∞®ÏóÖÏ≤¥Î™Ö", "Î™®Îç∏Î™Ö", "Î∂ÄÌíàÎ™Ö", "CTQ/P Í¥ÄÎ¶¨Ìï≠Î™©Î™Ö"]

    master_key_df_renamed = master_key_df.rename(columns={
        "Î∂ÄÌíà": "Î∂ÄÌíàÎ™Ö",
        "Í≥µÏ†ïCTQ/CTP Í¥ÄÎ¶¨ Ìï≠Î™©Î™Ö": "CTQ/P Í¥ÄÎ¶¨Ìï≠Î™©Î™Ö",
        "2Ï∞® ÏóÖÏ≤¥Î™Ö": "2Ï∞®ÏóÖÏ≤¥Î™Ö"
    })

    master_key_df_renamed = master_key_df_renamed.loc[:, ["Í¥ÄÎ¶¨Î≤àÌò∏"] + merge_keys]

    for key in merge_keys:
        results_df[key] = results_df[key].astype(str).str.strip()
        master_key_df_renamed[key] = master_key_df_renamed[key].astype(str).str.strip()

    merged_df = pd.merge(results_df, master_key_df_renamed, on=merge_keys, how='left')

    # Í¥ÄÎ¶¨Î≤àÌò∏Î•º Ï≤´ Î≤àÏß∏ Ïó¥Î°ú Ïù¥Îèô
    if "Í¥ÄÎ¶¨Î≤àÌò∏" in merged_df.columns:
        cols = merged_df.columns.tolist()
        cols.remove("Í¥ÄÎ¶¨Î≤àÌò∏")
        merged_df = merged_df[["Í¥ÄÎ¶¨Î≤àÌò∏"] + cols]

    return merged_df

# Ï†ÑÏ≤¥ ÌîÑÎ°úÏÑ∏Ïä§Î•º Ïã§ÌñâÌïòÎäî Ìï®Ïàò
def transform_data(
        input_file: BytesIO,
        master_file: BytesIO,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        search_cols: List[int] = list(range(0, 11))
) -> pd.DataFrame:
    info_df = pd.read_excel(input_file, sheet_name="Information")
    info_dict = info_df.set_index("Contents")['Value'].to_dict()

    df = pd.read_excel(input_file, sheet_name=info_dict["Data_sheet"], header=None)
    master_df = pd.read_excel(master_file, sheet_name="Master")

    date_row_idx = find_date_row(df)
    date_map = get_date_mapping(df, date_row_idx)

    df_result = extract_measurement_data(df, info_dict, date_map, date_row_idx, search_cols)
    df_result = add_management_code(df_result, master_df)

    if start_date and end_date:
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)
        df_result = df_result[
            (df_result["Ï∏°Ï†ïÏùºÏûê"] >= start_date) &
            (df_result["Ï∏°Ï†ïÏùºÏûê"] <= end_date)
        ]

    df_result_sorted = df_result.sort_values(by=["Ï∏°Ï†ïÏùºÏûê", "CTQ/P Í¥ÄÎ¶¨Ìï≠Î™©Î™Ö"]).reset_index(drop=True)
    return df_result_sorted

# Streamlit Ïï± Ïã§Ìñâ
st.title("Ï∏°Ï†ïÍ∞í Î≥ÄÌôò ÎèÑÍµ¨")

input_file = st.file_uploader("üìÑ Ï∏°Ï†ïÍ∞í Excel ÌååÏùº ÏóÖÎ°úÎìú", type=["xlsx"])
master_file = st.file_uploader("üìÑ ÎßàÏä§ÌÑ∞ ÌÇ§ Excel ÌååÏùº ÏóÖÎ°úÎìú", type=["xlsx"])
start_date = st.date_input("ÏãúÏûë ÎÇ†Ïßú", value=None)
end_date = st.date_input("Ï¢ÖÎ£å ÎÇ†Ïßú", value=None)

if input_file and master_file and start_date and end_date:
    try:
        df_result = transform_data(
            input_file=input_file,
            master_file=master_file,
            start_date=start_date,
            end_date=end_date
        )

        st.success("‚úÖ Î≥ÄÌôò ÏôÑÎ£å!")
        st.dataframe(df_result)

        towrite = BytesIO()
        with pd.ExcelWriter(towrite, engine='openpyxl') as writer:
            df_result.to_excel(writer, index=False, sheet_name="Î≥ÄÌôò")
        towrite.seek(0)

        st.download_button(
            label="üì• Í≤∞Í≥º Îã§Ïö¥Î°úÎìú",
            data=towrite,
            file_name="Î≥ÄÌôòÍ≤∞Í≥º.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    except Exception as e:
        st.error(f"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")
